---
title: "A-2021-10-14"
output:
  html_document:
    toc: true
---

```{r, include=FALSE}
knitr::opts_chunk$set(
  warning = FALSE
)
```

## Exercise 6.5
Suppose a $95 \%$ symmetric $t$-interval is applied to estimate a mean, but the sample data are non-normal. Then the probability that the confidence interval covers the mean is not necessarily equal to $0.95$. Use a Monte Carlo experiment to estimate the coverage probability of the $t$-interval for random samples of $\chi^{2}(2)$ data with sample size $n=20$. Compare your $t$-interval results with the simulation results in Example 6.4. (The $t$-interval should be more robust to departures from normality than the interval for variance.)

**Solution.**

The expectation of $\chi^2(2)$ distribution is $2$, while the variance is $4$.

**t-intervals**

We calculate t-intervals based on 1000 replicates.
```{r}
n <- 20
alpha <- 0.05

set.seed(1)

# calculate the half length of CIs
CL <- replicate(1000, expr = {
  x <- rchisq(n, df = 2)
  mu.hat <- mean(x)
  sd.hat <- sd(x)
  sqrt(n) * abs(mu.hat - 2) / sd.hat
})

# calculate coverage proportion
mean(CL < qt(1 - alpha / 2, df = n - 1))
```
The proportion that the genuine mean locates in the esitimated CI is $0.926$, which is a little bit less than the theorical one ($0.95$).

**interval for variance**

We calculate intervals for variance based on 1000 replicates.
```{r}
set.seed(1)
R <- 1000
n <- 20
alpha <- 0.05
cover <- numeric(R)
for (i in 1:R) {
  x <- rchisq(n, df = 2)
  UpperBound <- (n - 1) * var(x) / qchisq(alpha, df = n - 1)
  cover[i] <- (UpperBound > 4)
}
(ECP <- sum(cover) / R)
```
The proportion that the genuine variance locates in the esitimated CI is $0.797$, which is far less than the theoretical one ($0.95$).

As demonstrated by the above results ($0.926>0.797$), the t-interval is more robust to departures from normality than the interval for variance.

## Exercise 6.A
Use Monte Carlo simulation to investigate whether the empirical Type I error rate of the $t$-test is approximately equal to the nominal significance level $\alpha$, when the sampled population is non-normal. The $t$-test is robust to mild departures from normality. Discuss the simulation results for the cases where the sampled population is (i) $\chi^{2}(1)$, (ii) Uniform $(0,2)$, and (iii) Exponent$\operatorname{tial}(\mathrm{rate}=1)$. In each case, test $H_{0}: \mu=\mu_{0}$ vs $H_{0}: \mu \neq \mu_{0}$, where $\mu_{0}$ is the mean of $\chi^{2}(1)$, Uniform $(0,2)$, and Exponential $(1)$, respectively.

**Solution.**

The $t$-test for whether $\mu=\mu_0$ can be characterized as:
$$H_0:\mu=\mu_0\longleftrightarrow H_1:\mu\neq\mu_0$$
The test statistic:
$$T=\frac{\sqrt{n}(\bar{X}-\mu_0)}{S_X}$$
where $S_X=\sqrt{\frac{1}{n-1}\sum\limits_{i=1}^n(X_i-\bar{X})^2}$. Under normality assumption and $H_0$ , $T\sim t(n-1)$. For fixed significance level $\alpha$ , reject $H_0$ if $|t|>t_{\alpha/2}(n-1)$ .
   
We apply MC simulations to estimate type-I errors.

```{r}
set.seed(1)
m <- 10000  # replicates
n <- 100  # sample size
u <- 1  # population mean
alpha <- 0.05  # significance level

# Chisq(1)
error.Chisq <- replicate(m, expr = {
  x <- rchisq(n, 1)
  t <- sqrt(n) * (mean(x) - u) / sd(x)
  reject <- (abs(t) > qt(1 - alpha/2, n - 1))
})
Chisq.rate <- mean(error.Chisq)

# U(0,2)
error.Unif <- replicate(m, expr = {
  x <- runif(n, 0, 2)
  t <- sqrt(n) * (mean(x) - u) / sd(x)
  reject <- (abs(t) > qt(1 - alpha/2, n - 1))
})
Unif.rate <- mean(error.Unif)

# Exp(1)
error.Exp <- replicate(m, expr = {
  x <- rexp(n, 1)
  t <- sqrt(n) * (mean(x) - u) / sd(x)
  reject <- (abs(t) > qt(1 - alpha/2, n - 1))
})
Exp.rate <- mean(error.Exp)

cbind(Chisq.rate, Unif.rate, Exp.rate)
```

The empirical type I errors are close to the nominal level, demonstrating that the $t$-test is robust to mild departures from normality. The following plot shows how these three distributions depart from $N(1, 1)$. Intuitivly, the $\chi^{2}(1)$ departs normality most severely, while $U(0,2)$ looks more "normal". It coincides with the simulation results, that is, the deviation of the type I error from the nominal level is largest for $\chi^{2}(1)$ and smallest for $U(0,2)$.

```{r}
library(ggplot2)

p <- ggplot() +
  xlim(c(0, 2)) +
  geom_function(fun = dnorm, args = list(mean = 1), aes(color = "normal")) +
  geom_function(fun = dexp, aes(color = "exp")) +
  geom_function(fun = dchisq, args = list(df = 1), aes(color = "chisq"))+
  geom_function(fun = dunif, args = list(min = 0, max = 2) , aes(color = "unif"))

p
```



## Discussion
If we obtain the powers for two methods under a particular simulation setting with 10,000 experiments: say, $0.651$ for one method and $0.676$ for another method. We want to know if the powers are different at $0.05$ level.

1. What is the corresponding hypothesis test problem?
2. What test should we use? Z-test, two-sample t-test, paired-t test or McNemar test? Why?
3. Please provide the least necessary information for hypothesis testing.



**Solution.**

**1.** $H_0: \text{The two methods have the same power.} \leftrightarrow H_1: \text{The two methods have different powers.}$

**2.** McNemar test. Because it is equivalent to test whether the acceptance rates of the two methods are the same. Also, a contingency table can be naturally constructed as in **3**. 

**3.** For instance, consider the following contingency table. 
```{r}
mat <-
  matrix(c(6510, 3490, 10000, 6760, 3240, 10000, 13270, 6730, 20000), 3, 3,
         dimnames = list(
           c("Rejected", "Accepted", "total"),
           c("method A", "method B", "total")
         ))
mat
```
The test statistic:
$$\chi^2 = \sum_{i,j=1}^2 \frac{(n_{ij}-n_{i+} n_{+j}/n)^2}{n_{i+}n_{+j}/n} \rightarrow \chi^2_1.$$
Note that $\chi^2 = 13.9966$ and the p-value is $P(\chi^2_1 > \chi^2) = 0.0001831415 < 0.05$. Therefore, we reject the null hypothesis $H_0$, that is, the powers are different at $0.05$ level.

