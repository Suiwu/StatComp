# 第6次作业解答


## Question
Exercises 7.7, 7.8, 7.9, 7.B



## Answer

### 7.7, 7.8, 7.9
Refer to Exercise 7.6. Efron and Tibshirani discuss the following example [84, Ch. 7]. The five-dimensional scores data have a $5 \times 5$ covariance matrix $\Sigma$, with positive eigenvalues $\lambda_{1}>\cdots>\lambda_{5}$. In principal components analysis,
$$
\theta=\frac{\lambda_{1}}{\sum_{j=1}^{5} \lambda_{j}}
$$
measures the proportion of variance explained by the first principal component. Let $\hat{\lambda}_{1}>\cdots>\hat{\lambda}_{5}$ be the eigenvalues of $\hat{\Sigma}$, where $\hat{\Sigma}$ is the MLE of $\Sigma$. Compute the sample estimate
$$
\hat{\theta}=\frac{\hat{\lambda}_{1}}{\sum_{j=1}^{5} \hat{\lambda}_{j}}
$$
of $\theta$. 

+ (7.7) Use bootstrap to estimate the bias and standard error of $\hat{\theta}$.

+ (7.8) Refer to Exercise 7.7. Obtain the jackknife estimates of bias and standard
error of $\hat{\theta}$

+ (7.9) Refer to Exercise 7.7. Compute 95% percentile and BCa confidence intervals
for $\hat{\theta}$


```r
library(bootstrap)
library(boot)

set.seed(1)
n <- nrow(scor)
B <- 200

# estimate of theta
lambda_hat <- eigen(cov(scor))$values
theta_hat <- lambda_hat[1] / sum(lambda_hat)

###### bootstrap ######
theta <- function(data, k) {
  x <- data[k, ]
  lambda <- eigen(cov(x))$values
  theta <- lambda[1] / sum(lambda)
  theta
}

res_b <- boot(data = scor, statistic = theta, R = B)
theta_b <- res_b$t

# bias and standard error
bias_b <- mean(theta_b) - theta_hat
se_b <- sqrt(var(theta_b))

# 95% percentile and bca CIs
CIs <- boot.ci(res_b, conf = 0.95, type = c("perc", "bca"))
CI_perc <- CIs$percent[4:5]
CI_bca <- CIs$bca[4:5]

###### Jackknife ######
theta_j <- numeric(n)
for (i in 1:n) {
  x <- scor[-i, ]
  lambda <- eigen(cov(x))$values
  theta_j[i] <- lambda[1] / sum(lambda)
}

# bias and standard error
bias_j <- (n-1) * (mean(theta_j) - theta_hat)
se_j <- (n-1) * sqrt(var(theta_j) / n)

# Summary
res <- rbind(theta_hat, bias_b, se_b, bias_j, se_j)
rownames(res) <- c("estimate of theta", "bias_bootstrap", "se_bootstrap", "bias_jackknife", "se_jackknife")
knitr::kable(res)
```



|                  |          |
|:-----------------|---------:|
|estimate of theta | 0.6191150|
|bias_bootstrap    | 0.0016929|
|se_bootstrap      | 0.0474349|
|bias_jackknife    | 0.0010691|
|se_jackknife      | 0.0495523|

```r
cat("Percentile CI:", paste0("(",paste(CI_perc, collapse=", "),")"), "\n") 
```

```
## Percentile CI: (0.528377009929606, 0.713197868750667)
```

```r
cat("BCa CI:", paste0("(",paste(CI_bca, collapse=", "),")"), "\n") 
```

```
## BCa CI: (0.518723530142406, 0.712955398088904)
```


### 7.B

Repeat Project 7.A for the sample skewness statistic. Compare the coverage
rates for normal populations (skewness 0) and $χ^2(5)$ distributions (positive
skewness)


The true skewness of $N(0,1)$ and $\chi^2(5)$ are $0$ and $\sqrt{8/5}$, respectively.

```r
# skewness statistic
sk <- function(data, k) {
  x <- data[k]
  sum((x-mean(x))^3)/((length(x)-1)*sd(x)^3)
}

# true skewness
sk_norm <- 0
sk_chisq <- sqrt(8/5)

sim_once <- function(seed) {
# generate data
set.seed(seed)
x_norm <- rnorm(100)
x_chisq <- rchisq(100, df = 5)

##### bootstrap ########
B <- 200
res_norm <- boot(data = x_norm, statistic = sk, R = B)
res_chisq <- boot(data = x_chisq, statistic = sk, R = B)

# CIs
CI_norm <- boot.ci(res_norm, conf = 0.95, type = c("norm", "basic", "perc"))
CI_chisq <- boot.ci(res_chisq, conf = 0.95, type = c("norm", "basic", "perc"))

# coverage 
fl_norm_norm <- (sk_norm >= CI_norm$percent[4]) & (sk_norm <= CI_norm$percent[5])
fl_norm_basic <- (sk_norm >= CI_norm$basic[4]) & (sk_norm <= CI_norm$basic[5])
fl_norm_perc <- (sk_norm >= CI_norm$perc[4]) & (sk_norm <= CI_norm$perc[5])
fl_chisq_norm <- (sk_chisq >= CI_chisq$percent[4]) & (sk_chisq <= CI_chisq$percent[5])
fl_chisq_basic <- (sk_chisq >= CI_chisq$basic[4]) & (sk_chisq <= CI_chisq$basic[5])
fl_chisq_perc <- (sk_chisq >= CI_chisq$perc[4]) & (sk_chisq <= CI_chisq$perc[5])

return(c(fl_norm_norm = fl_norm_norm, fl_norm_basic = fl_norm_basic, fl_norm_perc = fl_norm_perc, fl_chisq_norm = fl_chisq_norm, fl_chisq_basic = fl_chisq_basic, fl_chisq_perc = fl_chisq_perc))
}

M <- 200  # replicates
res <- sapply(1:M, sim_once)
res_mean <- as.data.frame(rowMeans(res)) 
colnames(res_mean) <- NULL
rownames(res_mean) <- c("N(0,1)_normal", "N(0,1)_basic", "N(0,1)_perc", "Chisq(5)_norm", "Chisq(5)_basic", "Chisq(5)_perc")
cat("coverage rate", "\n")
```

```
## coverage rate
```

```r
knitr::kable(res_mean) 
```



|               |      |
|:--------------|-----:|
|N(0,1)_normal  | 0.905|
|N(0,1)_basic   | 0.880|
|N(0,1)_perc    | 0.905|
|Chisq(5)_norm  | 0.765|
|Chisq(5)_basic | 0.735|
|Chisq(5)_perc  | 0.765|
The table above shows the coverage rates respectively. For normal distribution, the empirical levels of bootstrap CIs are close to the nominal level ($0.95$), while for Chi square distribution, the empirical levels are much lower.  
